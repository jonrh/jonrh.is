# Javascript Node CircleCI 2.0 configuration file
# Check https://circleci.com/docs/2.0/language-javascript/ for more details
version: 2

jobs:
  build:
    docker:
      - image: circleci/node:10.19

    steps:
      - checkout

      - run:
          name: Install AWS command line interface to be able to deploy to S3 and CloudFront later
          # Installs the AWS command line interface v2 so we can deploy our frontend assets to S3
          # and invalidate the CloudFront cache in later steps. Another option to do this would be
          # to use the circleci/aws-cli orb but at the time of writing it can only install AWS cli
          # v1. There are no API differences but v1 requires Python and a bunch of other stuff
          # whereas AWS cli v2 is a self contained binary (faster and simpler to set up).
          #
          # https://circleci.com/docs/2.0/using-orbs/
          # https://circleci.com/orbs/registry/orb/circleci/aws-cli
          # https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-linux.html
          command: |
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            sudo ./aws/install

      - run:
          name: Install Node dependencies with Yarn
          command: yarn install

      - run:
          name: Build GatsbyJS site, i.e. generate the public/ folder
          command: yarn run build

      - run:
          name: Generate robots.txt files for either production and dev
          # Add robots.txt files to the public/ folder created in the previous step. Having a
          # compliant robots.txt file aids search engine optimization. When we are deploying to the
          # master branch we want to allow web crawlers access to the entire site. Note the missing
          # '/' after 'Disallow: '. This is the spec compliant way to indicate the site can be
          # crawled, that is it means nothing is disallowed to crawl (go nuts). If we are pushing
          # on the dev branch we add a robots.txt file that disallows all crawling. This is desired
          # since we don't want our dev environment to be indexed and searchable in search engines.
          # Notice that the second line is not indented. This is on purpose. Otherwise it will be
          # indented (creating a spec in-compliant robots.txt file).
          command: |
            if [ "${CIRCLE_BRANCH}" == "dev" ]; then
                echo 'User-agent: *
            Disallow: /' > public/robots.txt
            elif [ "${CIRCLE_BRANCH}" == "master" ]; then
                echo 'User-agent: *
            Disallow: ' > public/robots.txt
            else
                echo "Not dev or master branch so not deploying and no need for a robots.txt file"
            fi

      - deploy:
          name: Deploy site to AWS S3 and invalidate CloudFront cache
          # There are two deployments. If there is a new commit on the dev branch we push the
          # contents of the public/ folder to the dev.jonrh.is AWS S3 bucket. If the branch is
          # master we push the contents of the public/ folder to the jonrh.is bucket on AWS S3.
          # The --delete flag means we delete files in the S3 buckets if they don't exist in the
          # public/ folder.
          #
          # After each S3 bucket has been updated with the new content we invalidate the CloudFront
          # distributions (the thing that caches the static assets all over the world).
          # $CLOUDFRONTDEVJONRHISDISTID and $CLOUDFRONTJONRHISDISTID are environment variables
          # defined at circleci.com.
          #
          # The environment variable AWS_PAGER defined before the CloudFront commands is a
          # temporary fix for a bug in AWS cli v2. At the time of writing AWS cli v2 requires a
          # pager program, by default the command `less`. And lucky for us `less` is not available
          # in the CircleCI containers we run in. The good news is we can configure AWS cli to not
          # use any pager (the empty string "") and instead just print the entire output of results
          # out. For this case it's completely fine. See: https://github.com/aws/aws-cli/issues/5038
          command: |
            if [ "${CIRCLE_BRANCH}" == "dev" ]; then
                aws s3 sync public/ s3://dev.jonrh.is/ --delete
                AWS_PAGER="" aws cloudfront create-invalidation \
                  --distribution-id $CLOUDFRONTDEVJONRHISDISTID \
                  --paths '/*'
            elif [ "${CIRCLE_BRANCH}" == "master" ]; then
                aws s3 sync public/ s3://jonrh.is/ --delete
                AWS_PAGER="" aws cloudfront create-invalidation \
                  --distribution-id $CLOUDFRONTJONRHISDISTID \
                  --paths '/*'
            else
                echo "Not dev or master branch so not deploying"
            fi